{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Actual Positive Actual Negative\n",
      "Predicted Positive          TP: 43          FP: 34\n",
      "Predicted Negative          FN: 59          TN: 64\n",
      "\n",
      "Accuracy:\t0.54\n",
      "Precision:\t0.56\n",
      "Recall:\t\t0.42\n",
      "F-мера:\t\t0.48\n",
      "\n",
      "For score logreg:\t0.71918767507\n",
      "For score svm:\t\t0.708683473389\n",
      "For score knn:\t\t0.635154061625\n",
      "For score tree:\t\t0.691926770708\n",
      "\n",
      "For score logreg:\t0.63025210084\n",
      "For score svm:\t\t0.622807017544\n",
      "For score knn:\t\t0.606557377049\n",
      "For score tree:\t\t0.651785714286\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve\n",
    "\n",
    "# get data\n",
    "df = pandas.read_csv('classification.csv')\n",
    "T = np.array(df['true'])\n",
    "P = np.array(df['pred'])\n",
    "\n",
    "# calculate TP, FP, FN, TN\n",
    "TP = len([i for i in range(len(T)) if T[i] == 1 and P[i] == 1])\n",
    "FP = len([i for i in range(len(T)) if T[i] == 0 and P[i] == 1])\n",
    "TN = len([i for i in range(len(T)) if T[i] == 0 and P[i] == 0])\n",
    "FN = len([i for i in range(len(T)) if T[i] == 1 and P[i] == 0])\n",
    "\n",
    "df2 = pandas.DataFrame(np.matrix([['TP: ' + str(TP), 'FP: ' + str(FP)], ['FN: ' + str(FN), 'TN: ' + str(TN)]]), \n",
    "                       index=['Predicted Positive', 'Predicted Negative'], \n",
    "                       columns=['Actual Positive', 'Actual Negative'])\n",
    "print(df2)\n",
    "print()\n",
    "\n",
    "# calculate Accuracy\n",
    "print('Accuracy:', end = '\\t')\n",
    "print(round(accuracy_score(T, P), 2))\n",
    "\n",
    "# calculate Precision\n",
    "print('Precision:', end = '\\t')\n",
    "print(round(precision_score(T, P),2))\n",
    "\n",
    "# calculate Recall\n",
    "print('Recall:', end = '\\t\\t')\n",
    "print(round(recall_score(T, P),2))\n",
    "\n",
    "# calculate F-мера\n",
    "print('F-мера:', end = '\\t\\t')\n",
    "print(round(f1_score(T, P),2))\n",
    "\n",
    "# get new data\n",
    "df2          = pandas.read_csv('scores.csv')\n",
    "T_multi      = np.array(df2['true'])\n",
    "score_logreg = np.array(df2['score_logreg'])\n",
    "score_svm    = np.array(df2['score_svm'])\n",
    "score_knn    = np.array(df2['score_knn'])\n",
    "score_tree   = np.array(df2['score_tree'])\n",
    "print()\n",
    "print('For score logreg:', end = '\\t')\n",
    "print(roc_auc_score(T_multi, score_logreg))\n",
    "print('For score svm:', end = '\\t\\t')\n",
    "print(roc_auc_score(T_multi, score_svm))\n",
    "print('For score knn:', end = '\\t\\t')\n",
    "print(roc_auc_score(T_multi, score_knn))\n",
    "print('For score tree:', end = '\\t\\t')\n",
    "print(roc_auc_score(T_multi, score_tree))\n",
    "# max - score_logreg\n",
    "\n",
    "# calculate max(Precision) if min(Recall) = 70%\n",
    "print()\n",
    "\n",
    "# for score_logreg\n",
    "precision, recall, thresholds = precision_recall_curve(T_multi, score_logreg)\n",
    "max_precision = max([precision[i] for i in range(len(precision)) if recall[i] >= 0.7])\n",
    "print('For score logreg:', end = '\\t')\n",
    "print(max_precision)\n",
    "\n",
    "# for score_svm\n",
    "precision, recall, thresholds = precision_recall_curve(T_multi, score_svm)\n",
    "max_precision = max([precision[i] for i in range(len(precision)) if recall[i] >= 0.7])\n",
    "print('For score svm:', end = '\\t\\t')\n",
    "print(max_precision)\n",
    "\n",
    "# for score_knn\n",
    "precision, recall, thresholds = precision_recall_curve(T_multi, score_knn)\n",
    "max_precision = max([precision[i] for i in range(len(precision)) if recall[i] >= 0.7])\n",
    "print('For score knn:', end = '\\t\\t')\n",
    "print(max_precision)\n",
    "\n",
    "# for score_tree\n",
    "precision, recall, thresholds = precision_recall_curve(T_multi, score_tree)\n",
    "max_precision = max([precision[i] for i in range(len(precision)) if recall[i] >= 0.7])\n",
    "print('For score tree:', end = '\\t\\t')\n",
    "print(max_precision)\n",
    "# max - score_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
