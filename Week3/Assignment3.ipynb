{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged, iterations: 153!!!\n",
      "Gradient Descent normal: \n",
      "0.928095238095\n",
      "\n",
      "Converged, iterations: 7!!!\n",
      "Gradient Descent normal with l2-regularization: \n",
      "0.936095238095\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# set parameters\n",
    "k, C, evklid_dis, max_iters = 0.1, 10, 1e-5, 10000\n",
    "\n",
    "# get data\n",
    "df = pandas.read_csv('data-logistic.csv', header=None, names = ['y', 'x1', 'x2'])\n",
    "x1 = np.matrix(df['x1'])\n",
    "x2 = np.matrix(df['x2'])\n",
    "y  = np.matrix(df['y'])\n",
    "\n",
    "#sigmoid\n",
    "def sigmoid(z):\n",
    "    return (1 - 1/(1+math.exp(-z)))\n",
    "\n",
    "# set w1, w2\n",
    "w1, w2 = 0, 0\n",
    "n, m = np.shape(y)\n",
    "\n",
    "# create cost functions\n",
    "def cost_l2(y, x1, x2, w1, w2, C):\n",
    "    '''\n",
    "    with l2 regularization\n",
    "    '''\n",
    "    return sum([math.log(1 + math.exp(-y[0, i]*(x1[0, i]*w1 + x2[0, i]*w2))) for i in range(m-1)]) + 0.5*C*(w1**2+w2**2)\n",
    "\n",
    "def cost(y, x1, x2, w1, w2):\n",
    "    '''\n",
    "    without regularization\n",
    "    '''\n",
    "    return sum([math.log(1 + math.exp(-y[0, i]*(x1[0, i]*w1 + x2[0, i]*w2))) for i in range(m-1)])\n",
    "\n",
    "# calculate cost before start gradient descent\n",
    "Cost_l2 = cost_l2(y, x1, x2, w1, w2, C)\n",
    "Cost    = cost(y, x1, x2, w1, w2)\n",
    "\n",
    "# start gradient descent without regularization\n",
    "for j in range(max_iters):\n",
    "    w1 += (k/m)*sum([y[0, i]*x1[0, i]*sigmoid(y[0, i]*(x1[0, i]*w1 + x2[0, i]*w2)) for i in range(m-1)])\n",
    "    w2 += (k/m)*sum([y[0, i]*x2[0, i]*sigmoid(y[0, i]*(x1[0, i]*w1 + x2[0, i]*w2)) for i in range(m-1)])\n",
    "    Cost_new = cost(y, x1, x2, w1, w2)\n",
    "    if abs(Cost-Cost_new) <= evklid_dis:\n",
    "        print('Converged, iterations: ' + str(j) + '!!!')\n",
    "        break   \n",
    "    Cost = Cost_new\n",
    "    \n",
    "logistic = [1/(1+ math.exp(-x1[0, i]*w1 - x2[0, i]*w2)) for i in range(m)]\n",
    "print('Gradient Descent normal: ')\n",
    "print(roc_auc_score(np.array(df['y']), np.array(logistic)))\n",
    "print()\n",
    "\n",
    "# start gradient descent wit l2-regularization\n",
    "for j in range(max_iters):\n",
    "    w1 += (k/m)*sum([y[0, i]*x1[0, i]*sigmoid(y[0, i]*(x1[0, i]*w1 + x2[0, i]*w2)) for i in range(m-1)]) -  k*C*w1\n",
    "    w2 += (k/m)*sum([y[0, i]*x2[0, i]*sigmoid(y[0, i]*(x1[0, i]*w1 + x2[0, i]*w2)) for i in range(m-1)]) -  k*C*w2\n",
    "    Cost_new = cost_l2(y, x1, x2, w1, w2, C)\n",
    "    if abs(Cost_l2-Cost_new) <= evklid_dis:\n",
    "        print('Converged, iterations: ' + str(j) + '!!!')\n",
    "        break   \n",
    "    Cost_l2 = Cost_new\n",
    "    \n",
    "logistic = [1/(1+ math.exp(-x1[0, i]*w1 - x2[0, i]*w2)) for i in range(m)]\n",
    "print('Gradient Descent normal with l2-regularization: ')\n",
    "print(roc_auc_score(np.array(df['y']), np.array(logistic)))\n",
    "\n",
    "# We can see, that without regularization result will be 0.928. With l2-regularization - 0.936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
